{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 로지스틱 회귀분석(Logistic Regression)\n",
    " 공부 시간과 성적 사이의 관계는 좌표로 나타냈을 때 좌표의 형태가 직서으로 해결되는 선형 회귀를 사용하기 적합했습니다. 공부 시간에 따른 점수가 아닌 합격 여부로 발표되는 시험이 있을 경우 직선적으로 해결하기에는 적합하지 않습니다. 이 때 사용하는 로지스틱 회귀는 참과 거짓 중에 하나를 내놓는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부 시간 : [2, 4, 6, 8, 10, 12, 14], 합격 여부 : [0, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# x, y 데이터 값 : [공부 시간, 합격 여부]\n",
    "data = [[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]]\n",
    "xData = [i[0] for i in data] # 공부 시간\n",
    "yData = [i[1] for i in data] # 합격 시간\n",
    "print('공부 시간 : {}, 합격 여부 : {}'.format(xData, yData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=[-0.63436665], b=[-0.63436665]\n"
     ]
    }
   ],
   "source": [
    "# 기울기(a)와 y절편(b) 값을 랜덤한 값으로 정합니다. -> dtype은 tf.float64로 지정합니다. tf.float32로 지정하면 loss가 NaN이 출력됩니다.\n",
    "a = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "b = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('a={}, b={}'.format(sess.run(a), sess.run(b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시그모이드 방정식\n",
    "\n",
    "시그모이드 방정식의 오차를 계산하는 수식을 만듭니다.\n",
    "시그모이드 함수의 특징은 예측값(y)이 항상 0 또는 1입니다.\n",
    "\n",
    "참고 http://taewan.kim/post/sigmoid_diff/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.e : numpy에서 지수 값(2.718281828459045)을 의미하는 상수\n",
    "y = 1 / (1 + np.e ** -(a * xData + b))\n",
    "\n",
    "# 시그모이드 loss 값을 만듭니다.\n",
    "loss = -tf.reduce_mean(np.array(yData) * tf.log(y) + (1 - np.array(yData)) * tf.log(1-y))\n",
    "\n",
    "# 오차를 최소로 하는 값을 찾습니다.\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(0.25).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :     0, loss : 1.4007, a : 0.9181, b : -0.4982\n",
      "Epoch :  5000, loss : 0.0314, a : 2.1793, b : -15.0937\n",
      "Epoch : 10000, loss : 0.0180, a : 2.7496, b : -19.0957\n",
      "Epoch : 15000, loss : 0.0126, a : 3.1152, b : -21.6583\n",
      "Epoch : 20000, loss : 0.0096, a : 3.3846, b : -23.5463\n",
      "Epoch : 25000, loss : 0.0078, a : 3.5979, b : -25.0403\n",
      "Epoch : 30000, loss : 0.0066, a : 3.7743, b : -26.2759\n",
      "Epoch : 35000, loss : 0.0056, a : 3.9247, b : -27.3289\n",
      "Epoch : 40000, loss : 0.0050, a : 4.0557, b : -28.2461\n",
      "Epoch : 45000, loss : 0.0044, a : 4.1717, b : -29.0585\n",
      "Epoch : 50000, loss : 0.0040, a : 4.2758, b : -29.7874\n",
      "Epoch : 55000, loss : 0.0036, a : 4.3701, b : -30.4483\n",
      "Epoch : 60000, loss : 0.0033, a : 4.4565, b : -31.0527\n",
      "Epoch : 65000, loss : 0.0031, a : 4.5360, b : -31.6096\n",
      "Epoch : 70000, loss : 0.0029, a : 4.6097, b : -32.1258\n",
      "Epoch : 75000, loss : 0.0027, a : 4.6785, b : -32.6069\n",
      "Epoch : 80000, loss : 0.0025, a : 4.7428, b : -33.0573\n",
      "Epoch : 85000, loss : 0.0024, a : 4.8033, b : -33.4807\n",
      "Epoch : 90000, loss : 0.0022, a : 4.8603, b : -33.8801\n",
      "Epoch : 95000, loss : 0.0021, a : 4.9143, b : -34.2580\n",
      "Epoch : 100000, loss : 0.0020, a : 4.9655, b : -34.6168\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100001):\n",
    "        sess.run(gradient_descent)\n",
    "        if i % 5000 == 0:\n",
    "            print('Epoch : %5d, loss : %.4f, a : %.4f, b : %.4f' % (i, sess.run(loss), sess.run(a), sess.run(b)))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
